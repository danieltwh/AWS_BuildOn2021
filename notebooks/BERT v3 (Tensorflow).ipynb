{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Dataset/model_building/train/news_headlines_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2023, 2003, 1037, 3231, 1997, 1996, 14324, 2944, 102], [101, 4067, 2017, 2005, 1996, 3116, 2651, 102, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "# Testing the tokenizer\n",
    "\n",
    "text = [\"this is a test of the bert model\", \"thank you for the meeting today\"]\n",
    "\n",
    "sent_id = tokenizer.batch_encode_plus(text, padding=True, max_length = 8)\n",
    "\n",
    "\n",
    "print(sent_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['sentiment'], \n",
    "                                                                    random_state=42, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['sentiment'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=42, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff9ec249438>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_length = [len(x.split()) for x in train_text]\n",
    "\n",
    "sns.distplot(sent_length, bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_train = tokenizer.batch_encode_plus(train_text.tolist(), max_length = MAX_LENGTH, \n",
    "#                                           pad_to_max_length = True, truncation = True)\n",
    "\n",
    "# tokens_val = tokenizer.batch_encode_plus(val_text.tolist(), max_length = MAX_LENGTH, \n",
    "#                                           pad_to_max_length = True, truncation = True)\n",
    "\n",
    "# tokens_test = tokenizer.batch_encode_plus(test_text.tolist(), max_length = MAX_LENGTH, \n",
    "#                                           pad_to_max_length = True, truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "# bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
    "\n",
    "bert_model_name = 'bert_en_uncased_L-12_H-768_A-12'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "    'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "   'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'.\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3: 50.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3: 100.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3: 150.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3: 200.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3: 250.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3: 300.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3: 350.00MB\n",
      "INFO:absl:Downloading https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3: 400.00MB\n",
      "INFO:absl:Downloaded https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3, Total size: 434.04MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'.\n"
     ]
    }
   ],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\n",
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[-0.92169875 -0.39353448 -0.539317    0.68256223  0.43848467 -0.14021158\n",
      "  0.87747115  0.26043344 -0.63112956 -0.9999658  -0.2632002   0.85105294]\n",
      "Sequence Outputs Shape:(1, 128, 768)\n",
      "Sequence Outputs Values:[[ 0.19451556  0.2514169   0.19075055 ... -0.24845096  0.38568532\n",
      "   0.13290964]\n",
      " [-0.59478706 -0.39420387  0.25245696 ... -0.7694671   1.1564169\n",
      "   0.32475767]\n",
      " [ 0.006415   -0.15766485  0.54610234 ... -0.17451018  0.6028966\n",
      "   0.42672232]\n",
      " ...\n",
      " [ 0.21948308 -0.20927124  0.5386829  ...  0.24693576  0.18250978\n",
      "  -0.44427094]\n",
      " [ 0.0108023  -0.4455315   0.35990974 ...  0.3172279   0.23562793\n",
      "  -0.63070583]\n",
      " [ 0.29321173 -0.10581844  0.61147577 ...  0.20745769  0.1449466\n",
      "  -0.3535333 ]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, trainable=False, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=False, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(768, activation=\"relu\", name='fc1')(net)\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(512, activation=\"relu\", name = 'fc2')(net)\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(3, activation=\"softmax\", name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_classifier_model():\n",
    "#     text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "#     preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "#     encoder_inputs = preprocessing_layer(text_input)\n",
    "#     encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "#     outputs = encoder(encoder_inputs)\n",
    "#     net = outputs['pooled_output']\n",
    "#     net = tf.keras.layers.Dropout(0.1)(net)\n",
    "#     net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "#     return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(tf.constant(text_test))\n",
    "bert_raw_result = model(tf.constant(text_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.19858319 0.4181397  0.38327706]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(bert_raw_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.5494833  0.603038   0.59466326]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = tf.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.data.experimental.make_csv_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.data.TextLineDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['sentiment'], \n",
    "                                                                    random_state=42, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['sentiment'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=42, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=3)\n",
    "val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=3)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 1328\n",
      "Class 2: 636\n",
      "Class 3: 271\n"
     ]
    }
   ],
   "source": [
    "c1 = 0\n",
    "c2 = 0\n",
    "c3 = 0\n",
    "for x in train_labels:\n",
    "    if x[0] == 1:\n",
    "        c1+= 1\n",
    "    elif x[1] == 1:\n",
    "        c2 += 1\n",
    "    else:\n",
    "        c3 += 1\n",
    "        \n",
    "print(f\"Class 1: {c1}\\nClass 2: {c2}\\nClass 3: {c3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = tf.data.Dataset.from_tensor_slices(train_text.tolist())\n",
    "# train_Y = tf.data.Dataset.from_tensor_slices(train_labels.tolist())\n",
    "\n",
    "# val_ds = tf.data.Dataset.from_tensor_slices(val_text.tolist())\n",
    "# val_Y = tf.data.Dataset.from_tensor_slices(val_labels.tolist())\n",
    "\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices(test_text.tolist())\n",
    "# test_Y = tf.data.Dataset.from_tensor_slices(test_labels.tolist())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_ds = tf.data.Dataset.from_tensor_slices((train_text.tolist(), train_labels.tolist()))\n",
    "# # # train_Y = tf.data.Dataset.from_tensor_slices(train_labels.tolist())\n",
    "\n",
    "# val_ds = tf.data.Dataset.from_tensor_slices((val_text.tolist(), val_labels.tolist()))\n",
    "# # # val_Y = tf.data.Dataset.from_tensor_slices(val_labels.tolist())\n",
    "\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices((test_text.tolist(), test_labels.tolist()))\n",
    "# # # test_Y = tf.data.Dataset.from_tensor_slices(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: b'` For Nordea , moving into the new headquarters signifies the beginning of a new era .', Target: [0. 1.]\n",
      "Features: b\"Cramo Group 's financial targets for 2010-2013 are sales growth higher than 10 percent per year ; return on equity above 15 percent .\", Target: [0. 1.]\n",
      "Features: b'LEED is an internationally recognized green building certification system , developed by the U.S. Green Building Council .', Target: [1. 0.]\n",
      "Features: b'Both operating profit and net sales for the six-month period increased , respectively , from EUR13 .8 m and EUR143 .6 m , as compared to the corresponding period in 2007 .', Target: [0. 1.]\n",
      "Features: b'Seventy-three of those also have more extensive training in products built on the latest ArchestrA technologies , such as the Wonderware System Platform .', Target: [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# for feat, targ in train_ds.take(5):\n",
    "#     print ('Features: {}, Target: {}'.format(feat, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:using Adamw optimizer\n",
      "INFO:absl:gradient_clip_norm=1.000000\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_data).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "70/70 [==============================] - 825s 12s/step - loss: 0.9913 - categorical_accuracy: 0.5620 - val_loss: 0.8866 - val_categorical_accuracy: 0.5992\n",
      "Epoch 2/2\n",
      "70/70 [==============================] - 810s 12s/step - loss: 0.8460 - categorical_accuracy: 0.6094 - val_loss: 0.7973 - val_categorical_accuracy: 0.6472\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_text, y=train_labels, \n",
    "                    validation_data=(val_text, val_labels), \n",
    "                    epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 173s 12s/step - loss: 0.7804 - categorical_accuracy: 0.6555\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_text, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.780393123626709\n",
      "Accuracy: 0.6555323600769043\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "checkpoints/bert_v1_temp/part-00000-of-00001.data-00000-of-00001.tempstate7332029077314867094; No space left on device [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-338aa4eeb032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mversion_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'v1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msaved_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./bert_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./checkpoints/{saved_model_path}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite, save_format, options)\u001b[0m\n\u001b[1;32m   2222\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2223\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2224\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2225\u001b[0m       \u001b[0;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1219\u001b[0;31m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0m\u001b[1;32m   1220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1163\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m           \u001b[0;31m# initial read operations should be placed on the SaveableObject's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m           \u001b[0;31m# device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m           \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0msave_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1696\u001b[0m       return save_v2_eager_fallback(\n\u001b[1;32m   1697\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m   1699\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1716\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1718\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1719\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: checkpoints/bert_v1_temp/part-00000-of-00001.data-00000-of-00001.tempstate7332029077314867094; No space left on device [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "# Save the weights\n",
    "version_name = 'v1'\n",
    "saved_model_path = './bert_{}'.format(version_name)\n",
    "model.save_weights(f'./checkpoints/{saved_model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 910). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "bert_v1/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate2276669771186326027; No space left on device [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-630067aaa5da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msaved_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./bert_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2112\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m   def save_weights(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 151\u001b[0;31m                             signatures, options, save_traces)\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0;32m---> 90\u001b[0;31m           model, filepath, signatures, options)\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# Save all metadata to a separate file in the SavedModel directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, raise_metadata_warning, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         experimental_io_device=options.experimental_io_device)\n\u001b[1;32m   1113\u001b[0m     object_saver.save(\n\u001b[0;32m-> 1114\u001b[0;31m         utils_impl.get_variables_path(export_dir), options=ckpt_options)\n\u001b[0m\u001b[1;32m   1115\u001b[0m     builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n\u001b[1;32m   1116\u001b[0m                                                 export_dir)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1219\u001b[0;31m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0m\u001b[1;32m   1220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1163\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m           \u001b[0;31m# initial read operations should be placed on the SaveableObject's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m           \u001b[0;31m# device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m           \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, options)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0msave_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1696\u001b[0m       return save_v2_eager_fallback(\n\u001b[1;32m   1697\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1698\u001b[0;31m           ctx=_ctx)\n\u001b[0m\u001b[1;32m   1699\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1716\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1718\u001b[0;31m                              ctx=ctx, name=name)\n\u001b[0m\u001b[1;32m   1719\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1720\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: bert_v1/variables/variables_temp/part-00000-of-00001.data-00000-of-00001.tempstate2276669771186326027; No space left on device [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "version_name = 'v1'\n",
    "saved_model_path = './bert_{}'.format(version_name)\n",
    "\n",
    "model.save(saved_model_path, include_optimizer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_to_load = 'v1'\n",
    "toLoad_model_path = './bert_{}'.format(version_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.saved_model.load(toLoad_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = \"../Dataset\"\n",
    "\n",
    "# dataset_dir = os.path.join(dataset, \"model_building\" )\n",
    "\n",
    "# train_dir = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "# name = \"news_headlines_train.csv\"\n",
    "\n",
    "# df = pd.read_csv(os.path.join(train_dir, name))\n",
    "\n",
    "# remove unused folders to make it easier to load the data\n",
    "# remove_dir = os.path.join(train_dir, 'unsup')\n",
    "# shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset into train, validation and test sets\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['sentiment'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=df['sentiment'])\n",
    "\n",
    "\n",
    "# val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "#                                                                 random_state=2018, \n",
    "#                                                                 test_size=0.5, \n",
    "#                                                                 stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In addition , a further 29 employees can be la...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The authorisation is in force until the end of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The value of the deal was not disclosed .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You need to be ready when the window opens up ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Major Order in India Comptel Corporation has r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  In addition , a further 29 employees can be la...         -1\n",
       "1  The authorisation is in force until the end of...          0\n",
       "2          The value of the deal was not disclosed .          0\n",
       "3  You need to be ready when the window opens up ...          0\n",
       "4  Major Order in India Comptel Corporation has r...          1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# batch_size = 32\n",
    "# seed = 42\n",
    "\n",
    "# raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "#     '../Dataset/model_building/train',\n",
    "#     batch_size=batch_size,\n",
    "#     validation_split=0.2,\n",
    "#     subset='training',\n",
    "#     seed=seed)\n",
    "\n",
    "# class_names = raw_train_ds.class_names\n",
    "# train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "#     '../Dataset/model_building/train',\n",
    "#     batch_size=batch_size,\n",
    "#     validation_split=0.2,\n",
    "#     subset='validation',\n",
    "#     seed=seed)\n",
    "\n",
    "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "#     'aclImdb/test',\n",
    "#     batch_size=batch_size)\n",
    "\n",
    "# test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8' \n",
    "\n",
    "map_name_to_handle = {\n",
    "\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "   'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In addition , a further 29 employees can be laid off until further notice and the whole workforce can be laid off for short periods if needed .'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = df.iloc[0:10, 0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_preprocessed = bert_preprocess_model(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
      "Shape      : (10, 128)\n",
      "Word Ids   : [ 101 1999 2804 1010 1037 2582 2756 5126 2064 2022 4201 2125]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
